\begin{lemma}[Grothendieck's identity]\label{lem:G_id}
	Let $u,v\in\mathbb{R}^d$ be unit vectors. Let $r\in\mathbb{R}^d$ be a random unit vector chosen from $O(d)$-invariant probability distribution on the unit sphere. Then
	\begin{enumerate}
		\item[i,] $\mathbb{P}[\sgn(u^\top r)\neq\sgn(v^\top r)]=\frac{\arccos(u^\top v)}{\pi}$
		\item[ii,] $\mathbb{E}[\sgn(u^\top r)\sgn(v^\top r)]=\frac{2}{\pi}\arcsin(u^\top v).$
	\end{enumerate}
\end{lemma}
\begin{proof}
	Assume that $u$ and $v$ are linearly dependent. Since both, $u$ and $v$, are unit vectors, that is, either $u=v$, then $\arccos(u^\top v) = \arccos(1)=0$ or $u=-v$, then $\arccos(u^\top v) = \arccos(-1) = \pi$.
	%Bild von arccos
	Conversely assume that $u$ and $v$ are linearly independent, i.\,e. $\operatorname{dim}(\spn\{u,v\})=2$. Now project $r$ orthogonally on the plane spanned by $u$ and $v$. This gives us a vector $s\in \spn\{u,v\}$ such that $u^\top r = u^\top s$, $v^\top r = v^\top s$. The unit vector $s/\norm{s}$ is uniformly distributed on the unit circle by the $O(d)$-invariance of the probability distribution. 
\end{proof}

\begin{lemma}[Krivine's trick]\label{lem:krivines_trick}
	Let $u_1,\dots,u_m$,$v_1,\dots,v_n\in S^{m+n-1}$ be given. Then there are $u_1^\prime,\dots,u_m^\prime$,$v_1^\prime,\dots,v_n^\prime\in S^{m+n-1}$ so that
	\begin{equation}
		\mathbb{E}[\sgn((u_i^\prime)^\top r)\sgn((v_j^\prime)^\top r)] = \beta u_i^\top v_j,
	\end{equation}		
	with $\beta = \frac{2}{\pi} \ln (1+\sqrt{2}).$
\end{lemma}

For the proof of \ref{lem:krivines_trick} we need to use the tensor product. \textcolor{red}{We have already seen the tensor product for complex vector spaces. Now we give an alternative definition for the $\mathbb{R}^n$.} The $\mathbb{R}^n$ is an $n$-dimensional Euclidean space with inner product \sclr{\cdot}{\cdot} and orthonormal basis $e_1,\dots,e_n$.
Then the \emph{k-th tensor product of $\mathbb{R}^n$} is denoted by $(\mathbb{R}^n)^{\tensor k}$ and it is a Euclidean  vector space of dimension $n^k$ with orthonormal basis $e_{i_1}\tensor e_{i_2} \tensor \cdots \tensor e_{i_k}$, $i_j\in\{1,\dots,n\}$. In particular
\begin{align}
	(e_{i_1}\tensor \cdots \tensor e_{i_k})^\top (e_{j_1}\tensor \cdots \tensor e_{j_k}) 
	&= \prod_{r=1}^k e_{i_r}^\top e_{j_r}\nonumber\\
	&=\begin{cases}
		1 & , \text{ if } i_r=j_r \text{ for all } r=1,\dots,n,\\
		0 & , \text{ otherwise},
	\end{cases} \label{eq:orthonormtensor}
\end{align}
and for $v\in\mathbb{R}^n$ with $v=v_1e_1+\cdots +v_ne_n$ we define $v^{\tensor k} \in (\mathbb{R}^n)^{\tensor k}$ by 
\begin{equation}
	v^{\tensor k} = (v_1e_1 + \cdots + v_ne_n) \tensor \cdots \tensor (v_1e_1 + \cdots + v_ne_n) = \sum_{i_1,\dots,i_k} v_{i_1}\cdots v_{i_k} e_{i_1}\tensor\cdots\tensor e_{i_k},
\end{equation}
where the last equation follows by the distributive law (identity ii, of the tensor product). 
Thus, for $v,w\in\mathbb{R}^n$ 
\begin{align}
	(v^{\tensor k})^\top w^{\tensor k}
	&\overset{\textcolor{white}{\eqref*{eq:orthonormtensor}}}{=} \sum_{i_1,\dots,i_k} v_{i_1}\cdots v_{i_k}\left(e_{i_1}\tensor\cdots\tensor e_{i_k}\right)^\top \sum_{j_1,\dots,j_k} w_{j_1}\cdots w_{j_k}(e_{j_1}\tensor\cdots\tensor e_{j_k}) \nonumber\\
	&\overset{\textcolor{white}{\eqref*{eq:orthonormtensor}}}{=} \sum_{i_1,\dots,i_k} v_{i_1}\cdots v_{i_k} \sum_{j_1,\dots,j_k} w_{j_1}\cdots w_{j_k} \left(e_{i_1}\tensor\cdots\tensor e_{i_k}\right)^\top (e_{j_1}\tensor\cdots\tensor e_{j_k}) \nonumber\\
	&\overset{\eqref{eq:orthonormtensor}}{=} \sum_{i_1,\dots,i_k} v_{i_1}\cdots v_{i_k}w_{i_1}\cdots w_{i_k} \nonumber\\
	&\overset{\textcolor{white}{\eqref*{eq:orthonormtensor}}}{=}(\sum_{i=1}^n v_iw_i)^k = (v^\top w)^k \label{eq:kth_tensor}
\end{align}
\begin{proof}
	Define the function $E: [-1,+1] \to [-1,+1]$ by $E(t)=\frac{2}{\pi}\arcsin(t)$. Due to Grothendieck's identity (Lemma \ref{lem:G_id}):
	\begin{align*}
		E((u_i^\prime)^\top v_j^\prime ) &= \mathbb{E}[\sgn((u_i^\prime)^\top r)\sgn((v_j^\prime)^\top r)]\\
		&\overset{!}{=}\beta u_i^\top v_j,
	\end{align*}
	where $r\in\mathbb{R}^d$ is a random unit vector chosen form the $O(d)$-invariant probability distribution on the unit sphere.\\
	
	Idea: To find $\beta,u_i^\prime,v_j^\prime$ we invert $E$:
	\[
		(u_i^\prime)^\top v_j^\prime = E^{-1} (\beta u_i^\top v_j)	
	\]
	with 
	\begin{align*}
		E^{-1}(t) &= \sin(\pi/2 \cdot t) \\
		&= \sum_{k=0}^\infty \underbrace{\frac{(-1)^{2k+1}}{(2k+1)!}\left(\frac{\pi}{2}\right)^{2k+1}}_{g_{2k+1}}  t^{2k+1}
	\end{align*}
	which is valid for all $t\in[-1,+1]$.
	
	Define the infinite-dimensional Hilbert space
	\begin{equation}
		H= \bigoplus_{r=0}^\infty (\mathbb{R}^{m+n})^{\tensor 2k+1}.
	\end{equation}
	\textcolor{red}{Begruenden, dass H gross genug ist?}
	
	Define $u_i^\prime, v_j^\prime\in H$ componentwise:
	\begin{align*}
		(u_i^\prime)_k &= \sgn(g_{2k+1}) \sqrt{\modul{g_{2k+1}}\beta^{2k+1}}\, u^{\tensor 2k+1} \\
		(v_j^\prime)_k &= \sqrt{\modul{g_{2k+1}}\beta^{2k+1}} \,v^{\tensor 2k+1}
	\end{align*}
	\textcolor{red}{woher sind u und v?}
	Then 
	\begin{align*}
		(u_i^\prime)^\top v_j^\prime &\overset{\textcolor{white}{\eqref*{eq:kth_tensor}}}{=} \sum_{k=0}^\infty g_{2k+1} \beta^{2k+1}(u^{\tensor 2k+1})^\top v^{\tensor 2k+1} \\
		&\overset{\eqref{eq:kth_tensor}}{=} \sum_{k=0}^\infty g_{2k+1} \beta^{2k+1} (u^\top v)^{2k+1} \\
		&\overset{\textcolor{white}{\eqref*{eq:kth_tensor}}}{=} E^{-1}(\beta u_i^\top v_j).
	\end{align*}
	Hence, $\beta$ is defined by the condition
	\[
		1 = (u_i^\prime)^\top u_i = (v_j^\prime)^\top v_j 
		%= \sum_{k=0}^\infty \modul{g_{2k+1}} \beta^{2k+1} 
		= \sum_{k=0}^\infty \frac{1}{(2k+1)!}\left(\frac{\pi}{2}\right)^{2k+1}\beta^{2k+1}=\sinh(\frac{\pi}{2}\beta)
	\]
	and
	\[
		\beta = \frac{2}{\pi} \arcsinh(1) = \frac{2}{\pi}\ln(1+\sqrt(2)),	
	\]
	since $\arcsinh (t) = \ln(t+\sqrt{t^2+1})$.
	\textcolor{red}{Gram matrix}
\end{proof}
\newpage